{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6ed2b63f",
      "metadata": {
        "id": "6ed2b63f"
      },
      "source": [
        "A convolutional neural network uses featured maps, cooled featured maps etc and then flattens out the image (flattenend layer) and then passes it onto neurons.\n",
        "To understand train and deploy our cnn we use the MNIST datset.\n",
        "Each image here is 28x28 pixels, it makes it a 28x28 array --> The background is all 0.\n",
        "Then for the image itself---> The darkest shad will be 1 and all the other shades will be in relation to this. This identification of the border of these images is feature mapping.\n",
        "Basic skeleton of a CNN:\n",
        "Input ---> (Convolution-->Pooling)n ---> Flattened layer ---> Fully connected neurons --> Output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aafa677",
      "metadata": {
        "id": "8aafa677"
      },
      "source": [
        "Image filters and kernels:\n",
        "A kernel is a smaller matrix that goes around the bigger image matrix of 0s and <1s performing addition or multiplication of matrices around them.\n",
        "Suppose you have:\n",
        "Input image: 6 × 6\n",
        "Kernel: 3 × 3\n",
        "Steps:\n",
        "Place the kernel on the top-left of the image\n",
        "Multiply overlapping values\n",
        "Add them --> one number\n",
        "Slide the kernel --> repeat\n",
        "The result is a feature map. Each of these kernels will learn to recognise a kind of pattern.\n",
        "Stride --> How many steps a kernel moves in each epoch\n",
        "Padding --> Border operations: Valid (Shrinked o/p), Same (No change)\n",
        "Filter --> This is an operation done on an image using an appropriate kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f94316e8",
      "metadata": {
        "id": "f94316e8"
      },
      "source": [
        "We use cnn because neurons are locally connected making it a lot more efficient and faster. Each kernels condense to pooling that further goes to local neurons.\n",
        "Each picture is a 3D tensor of: height, width and color channels i.e. 3 layers\n",
        "but each RGB splits as a seperater parameter i.e. HWR, HWG, HWB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "253a1710",
      "metadata": {
        "id": "253a1710"
      },
      "source": [
        "Pooling:\n",
        "Downsampling a convolutional matrix even more. Methods like maxpooling and avgpooling are used.\n",
        "The kernel moves along forming the convolution and the max value of each kernel is used and then pooled (DANGERRR losing data is a possibility)\n",
        "Avg takes the avg of the elements in each kernel.\n",
        "torch / nn → brain\n",
        "datasets / DataLoader → eyes\n",
        "transforms → glasses\n",
        "optimizer / loss → learning\n",
        "matplotlib / sklearn → self-reflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "550437d1",
      "metadata": {
        "id": "550437d1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a157c3b",
      "metadata": {
        "id": "4a157c3b"
      },
      "source": [
        "We need to convert MNIST 2d images into tensors of 4D for CNN operations (Number,height,width,colour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3e07baf3",
      "metadata": {
        "id": "3e07baf3"
      },
      "outputs": [],
      "source": [
        "data_dir = \"Data/mnist\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89152bae",
      "metadata": {
        "id": "89152bae"
      },
      "source": [
        "Now, we will transform the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "984f8fe1",
      "metadata": {
        "id": "984f8fe1"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5,), (0.5,))])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df77d2c2",
      "metadata": {
        "id": "df77d2c2"
      },
      "source": [
        "Normalise shifts the data around 0 and then the model learns. The parameters are mean, std her the numbers are known for MNIST but it can ofc be calculated.\n",
        "mean = dataset.data.float().mean() / 255\n",
        "std = dataset.data.float().std() / 255\n",
        "Also to normalise a pixel (x) means x(n) = (x-mean)/std\n",
        "Now load test and train datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "08abf30a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08abf30a",
        "outputId": "53b2d346-543f-480c-8540-dbc469e94126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.02MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 14.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root=data_dir, train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4548d6b2",
      "metadata": {
        "id": "4548d6b2"
      },
      "source": [
        "Now wrap these datasets in dataloaders. Basically this is creating those kernels so that the data will move in batches and batches only.\n",
        "The batch_size is at 64 because its optimal this basically describes how many elements at once.\n",
        "Shuffling is the equivalent of back propagation in a BNN, therefore we dont need it on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "91ccdbdc",
      "metadata": {
        "id": "91ccdbdc"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b79090",
      "metadata": {
        "id": "31b79090"
      },
      "source": [
        "Now verify it's correct loading (or) sanity check, the same can be used in a for loop but this will shorten the code and verify faster\n",
        "NOTE:\n",
        "DataLoader is NOT a list nor a datset it's an iterator indexing will fail here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "542349d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "542349d1",
        "outputId": "3e903f24-9811-41ba-bfa2-e166ccd81139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d606918f",
      "metadata": {
        "id": "d606918f"
      },
      "source": [
        "Now we build the convolutional layer and the pooling layer. Layer by layer\n",
        "nn.conv2d(inputsize, outputsize, kernelsize, stride) -- can also give padding here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a6fd0b67",
      "metadata": {
        "id": "a6fd0b67"
      },
      "outputs": [],
      "source": [
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da27e9d",
      "metadata": {
        "id": "6da27e9d"
      },
      "source": [
        "Now we can take a single mnist record and carry forward our operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e918d26e",
      "metadata": {
        "id": "e918d26e"
      },
      "outputs": [],
      "source": [
        "for i, (X_train, y_train) in enumerate(train_loader):\n",
        "    break\n",
        "x = X_train[0].view(1, 1, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "725fdf1b",
      "metadata": {
        "id": "725fdf1b"
      },
      "source": [
        "Now push it through the convolution using relu or rectified linear units. We can pass it without specifying padding because in MNIST data the image core is in the middle of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "464efe32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "464efe32",
        "outputId": "ab973f4c-ae9b-4fe1-ea1e-1043f0da02c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 26, 26])\n"
          ]
        }
      ],
      "source": [
        "x = F.relu(conv1(x))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c83915",
      "metadata": {
        "id": "a6c83915"
      },
      "source": [
        "After passing it through convolutional layer now we can pass it through the pooling layer after convolutions, (x,2,2) where 2,2 are kernel size and stride"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0f3839ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f3839ae",
        "outputId": "e09a6a78-5c79-4bca-c0a1-87e9a87f5dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 13, 13])\n"
          ]
        }
      ],
      "source": [
        "x = F.max_pool2d(x, 2, 2)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93b6f41",
      "metadata": {
        "id": "b93b6f41"
      },
      "source": [
        "Now the next convolutional layer and pooling layer because we want to build 2 of these. Make sure to use the same x variable because its all linear i.e. one after another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5b4bfe7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b4bfe7c",
        "outputId": "159e9153-5738-47f1-e6df-75e1a0b942f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 11, 11])\n",
            "torch.Size([1, 16, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "x = F.relu(conv2(x))\n",
        "print(x.shape)\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "print(x.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
