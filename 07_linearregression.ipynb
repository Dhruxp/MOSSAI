{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b09a77c",
      "metadata": {
        "id": "0b09a77c"
      },
      "source": [
        "Linear regressions help us make predictions on the future, based on past data that is training phase.\n",
        "Here we use the diabetes data set in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "16365bfa",
      "metadata": {
        "id": "16365bfa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a237f01",
      "metadata": {
        "id": "4a237f01"
      },
      "source": [
        "Now for implementing, convert this data into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9c8be187",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c8be187",
        "outputId": "9026fb56-8226-4a51-8d99-9391f8d29e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
            "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
            "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
            "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
            "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
            "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
            "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
            "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
            "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
            "\n",
            "           s4        s5        s6  \n",
            "0   -0.002592  0.019907 -0.017646  \n",
            "1   -0.039493 -0.068332 -0.092204  \n",
            "2   -0.002592  0.002861 -0.025930  \n",
            "3    0.034309  0.022688 -0.009362  \n",
            "4   -0.002592 -0.031988 -0.046641  \n",
            "..        ...       ...       ...  \n",
            "437 -0.002592  0.031193  0.007207  \n",
            "438  0.034309 -0.018114  0.044485  \n",
            "439 -0.011080 -0.046883  0.015491  \n",
            "440  0.026560  0.044529 -0.025930  \n",
            "441 -0.039493 -0.004222  0.003064  \n",
            "\n",
            "[442 rows x 10 columns]\n"
          ]
        }
      ],
      "source": [
        "data = load_diabetes()\n",
        "my_df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "print(my_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56be3f35",
      "metadata": {
        "id": "56be3f35"
      },
      "source": [
        "We are trying to predict the values in the next year using LR. To verify we can import the already availible data in this and then predict and cross verify the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c3801c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3801c35",
        "outputId": "e35df199-911d-41b9-d960-ec082a24b355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
            "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
            "2    0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
            "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
            "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
            "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
            "439  0.041708  0.050680 -0.015906  0.017293 -0.037344 -0.013840 -0.024993   \n",
            "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
            "441 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
            "\n",
            "           s4        s5        s6  Target  \n",
            "0   -0.002592  0.019907 -0.017646   151.0  \n",
            "1   -0.039493 -0.068332 -0.092204    75.0  \n",
            "2   -0.002592  0.002861 -0.025930   141.0  \n",
            "3    0.034309  0.022688 -0.009362   206.0  \n",
            "4   -0.002592 -0.031988 -0.046641   135.0  \n",
            "..        ...       ...       ...     ...  \n",
            "437 -0.002592  0.031193  0.007207   178.0  \n",
            "438  0.034309 -0.018114  0.044485   104.0  \n",
            "439 -0.011080 -0.046883  0.015491   132.0  \n",
            "440  0.026560  0.044529 -0.025930   220.0  \n",
            "441 -0.039493 -0.004222  0.003064    57.0  \n",
            "\n",
            "[442 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "my_df['Target'] = data.target\n",
        "print(my_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2147c58c",
      "metadata": {
        "id": "2147c58c"
      },
      "source": [
        "We now need to split all these attributes to X, y variables. X --> all the values that need to be compared.\n",
        "y --> Known result i.e. The impact of these attributes on the target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cbbb7c1e",
      "metadata": {
        "id": "cbbb7c1e"
      },
      "outputs": [],
      "source": [
        "X = my_df.drop('Target',axis=1)\n",
        "y = my_df['Target']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e82cd4d7",
      "metadata": {
        "id": "e82cd4d7"
      },
      "source": [
        "Now split the data into training and testing in an 80:20 ratio. This can be done using scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "51a82e86",
      "metadata": {
        "id": "51a82e86"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d990347f",
      "metadata": {
        "id": "d990347f"
      },
      "source": [
        "We need to do both a X train and test as well as y train and test as we have 2 different var. Test size = 0.2 is 20%. Random_state defines the manual seed. We can see the dimensions of both these datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bcc70762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcc70762",
        "outputId": "1aae7882-636e-4b74-c3f2-8abefd2da1ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training:  (353, 10) (353,)\n",
            "Testing:  (89, 10) (89,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "print(\"Training: \", X_train.shape,y_train.shape)\n",
        "print(\"Testing: \", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98129085",
      "metadata": {},
      "source": [
        "Now we can actually create the linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b14812ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84631948",
      "metadata": {},
      "source": [
        "This creates the linear regression instance and now we need to train our data and test our data on this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a031818a",
      "metadata": {},
      "outputs": [],
      "source": [
        "lr.fit(X_train,y_train) #This is the fit function "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a52904",
      "metadata": {},
      "source": [
        "After the training on this is done we can go on to predicting on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45e1745",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = lr.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f49ae5f8",
      "metadata": {},
      "source": [
        "After we have done this part, we can actually compare with the real values because we already have the Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c97e1d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "#These will show the performance of the model also called performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a4abf24",
      "metadata": {},
      "outputs": [],
      "source": [
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mea = mean_absolute_error(y_test,y_pred)\n",
        "intercept = lr.intercept_\n",
        "print(\"r2: \", r2)\n",
        "print(\"mea: \", mea)\n",
        "print(\"mse: \", mse)\n",
        "print(\"Intercept: \", intercept)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "433308a2",
      "metadata": {},
      "source": [
        "Here the r2 score shows how well the model fits the data, higher the better, lies between 0-1. Mathematically variance of the dependent variable (target here) explained by the independent variable\n",
        "\n",
        "The mean squared error: The avg squared distance between the predicted and actual values, here the lower the better because if it's closer to the line through the scatter plot it shows accuracy.\n",
        "\n",
        "The mean absolute distance: Avg absolute distance between predicted and actual values. Here the lower the better again\n",
        "\n",
        "Intercept_ This is the starting point of the regression line on the y-axis. Mathematically the value of dependent variable (target) when the value of the independent variable is 0. \n",
        "If positive, the target increases as the features increase\n",
        "If negative, the target decreases as the features decrease"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab09407a",
      "metadata": {},
      "source": [
        "We can also graph these. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64962c70",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#y --> predictions, x --> actaul values(target)\n",
        "#If the model fits well the points should lie close to the regression line\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], color=\"red\")\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\") \n",
        "plt.title(\"Predicted vs Actual values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968fa5d4",
      "metadata": {},
      "source": [
        "Now we can plot residuals. Residuals are plotted against the predicted values of the target variables. If the model is a good fit there will be a random point scatter around 0 in the residual plot with no noticable trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c21360",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(y_pred,y_test-y_pred,alpha=0.5)\n",
        "plt.xlabel(\"Predictions\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual plots\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
